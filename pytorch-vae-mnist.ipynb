{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.io import read_image\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters  \n",
    "* $x$ is a observed variable in dataset $X=\\{x^{(i)}\\}^N_{i=1}$ consisting of $N$ i.i.d. samples, $x\\in\\mathbb{R^{\\text{x\\_dim}}}$  \n",
    "* $z$ is a latent variable, $z\\in\\mathbb{R^{\\text{z\\_dim}}}$ such that $z{\\sim}q_{\\phi}(z|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file_train = \"./data/train/labels.csv\"\n",
    "img_dir_train = \"./data/train/images/\"\n",
    "annotations_file_test = \"./data/test/labels.csv\"\n",
    "img_dir_test = \"./data/test/images/\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "workers = 1\n",
    "learning_rate = 1E-4\n",
    "batch_size = 50\n",
    "epochs = 30\n",
    "# x_dim = 784 is defined by dataset\n",
    "z_dim = 64\n",
    "hidden_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file) \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = torch.flatten(read_image(img_path)).float() / 255.0\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(x_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.log_sigma = nn.Linear(hidden_dim, z_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.leaky_relu(self.linear1(x))\n",
    "        mean = self.mu(h)\n",
    "        log_var = self.log_sigma(h)\n",
    "        return mean, log_var\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, x_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, x_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.leaky_relu(self.linear1(z))\n",
    "        x_hat = torch.sigmoid(self.output(h))\n",
    "        return x_hat\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def reparameterise(self, mean, var):\n",
    "        epsilon = torch.randn_like(var)\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterise(mean, torch.exp(0.5 * log_var))\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var\n",
    "    \n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reconstruction_error = nn.functional.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return kl_divergence + reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MNISTDataset(annotations_file_train, img_dir_train)\n",
    "dataset_test = MNISTDataset(annotations_file_test, img_dir_test)\n",
    "loader_train = DataLoader(Subset(dataset_train, range(10)), batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "loader_test = DataLoader(Subset(dataset_test, range(1)), batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "x_dim = len(dataset_train[0][0])\n",
    "encoder = Encoder(x_dim, hidden_dim, z_dim)\n",
    "decoder = Decoder(z_dim, hidden_dim, x_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.to(device)\n",
    "optimiser = Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE...\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete.\tAverage loss: 109.72337890625\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete.\tAverage loss: 109.301396484375\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete.\tAverage loss: 109.03318359375\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete.\tAverage loss: 108.70408203125\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete.\tAverage loss: 108.27322265625\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete.\tAverage loss: 107.952275390625\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete.\tAverage loss: 107.443984375\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete.\tAverage loss: 107.492666015625\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete.\tAverage loss: 106.846904296875\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete.\tAverage loss: 106.821162109375\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 complete.\tAverage loss: 106.2800390625\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 complete.\tAverage loss: 105.751435546875\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 complete.\tAverage loss: 105.549365234375\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 complete.\tAverage loss: 105.299716796875\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 complete.\tAverage loss: 105.08146484375\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 complete.\tAverage loss: 104.6973828125\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 complete.\tAverage loss: 104.2399609375\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 complete.\tAverage loss: 103.493056640625\n",
      "Epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 complete.\tAverage loss: 103.244736328125\n",
      "Epoch 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 complete.\tAverage loss: 103.387490234375\n",
      "Epoch 21:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 complete.\tAverage loss: 103.2290625\n",
      "Epoch 22:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 complete.\tAverage loss: 102.367451171875\n",
      "Epoch 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 complete.\tAverage loss: 102.129453125\n",
      "Epoch 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 complete.\tAverage loss: 101.92791015625\n",
      "Epoch 25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 complete.\tAverage loss: 101.7356640625\n",
      "Epoch 26:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 complete.\tAverage loss: 101.4321875\n",
      "Epoch 27:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 complete.\tAverage loss: 100.22669921875\n",
      "Epoch 28:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 complete.\tAverage loss: 100.984365234375\n",
      "Epoch 29:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 complete.\tAverage loss: 100.16048828125\n",
      "Epoch 30:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 complete.\tAverage loss: 99.98029296875\n",
      "Traning complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training VAE...\")\n",
    "vae.train()\n",
    "i = 1\n",
    "curr_loss = None\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"Epoch {i}:\")\n",
    "    for batch in tqdm(loader_train):\n",
    "        optimiser.zero_grad()\n",
    "        x = batch[0]\n",
    "        x.to(device)\n",
    "        x_hat, mean, log_var = vae(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(f\"Epoch {i} complete.\\tAverage loss: {total_loss / batch_size}\")\n",
    "    i += 1\n",
    "    curr_loss = total_loss\n",
    "print(\"Traning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = OrderedDict([\n",
    "    (\"annotations_file_train\", annotations_file_train),\n",
    "    (\"img_dir_train\", img_dir_train),\n",
    "    (\"annotations_file_test\", annotations_file_test),\n",
    "    (\"img_dir_test\", img_dir_test),\n",
    "    (\"device\", device),\n",
    "    (\"workers\", workers),\n",
    "    (\"learning_rate\", learning_rate),\n",
    "    (\"batch_size\", batch_size),\n",
    "    (\"epochs\", epochs),\n",
    "    (\"z_dim\", z_dim),\n",
    "    (\"hidden_dim\", hidden_dim)\n",
    "])\n",
    "log = {\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"loss\": curr_loss\n",
    "}\n",
    "torch.save(vae.state_dict(), \"vae-state-dict.pt\")\n",
    "torch.save(optimiser.state_dict(), \"optimiser-state-dict.pt\")\n",
    "with open(\"log.json\", 'w') as fp:\n",
    "    json.dump(log, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc-mnist-vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
